{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bokeh.models import ColumnDataSource\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.io import show, output_notebook\n",
    "from bokeh.layouts import gridplot\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"CT_Accidents.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "25163\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "3640\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Severity                   0\n",
       "Temperature(F)             0\n",
       "Humidity(%)                0\n",
       "Pressure(in)               0\n",
       "Visibility(mi)             0\n",
       "Wind_Speed(mph)            0\n",
       "Precipitation(tenth_in)    0\n",
       "Weather_Condition          0\n",
       "Amenity                    0\n",
       "Bump                       0\n",
       "Crossing                   0\n",
       "Give_Way                   0\n",
       "Junction                   0\n",
       "No_Exit                    0\n",
       "Railway                    0\n",
       "Roundabout                 0\n",
       "Station                    0\n",
       "Stop                       0\n",
       "Traffic_Calming            0\n",
       "Traffic_Signal             0\n",
       "Turning_Loop               0\n",
       "Night                      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 673,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in df.columns:\n",
    "    print(df[i].isnull().values.sum())\n",
    "\n",
    "\n",
    "df[features].isnull().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original dataset included 49 states worth of accident data, so I restricted it to CT and saved it as a new csv so we don't have to load a 1Gb csv each time we open it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comparison_plot(x,Y, Yhat):\n",
    "    '''Plots Predicted vs True values for analysis of regression'''\n",
    "    comparison_plot = figure(title='Difference between Measured and Predicted Values')\n",
    "    comparison_plot.xaxis.axis_label='x'\n",
    "    comparison_plot.yaxis.axis_label='Yhat-Y'\n",
    "    comparison_plot.scatter(x=x,y=Yhat-Y)\n",
    "    comparison_plot.line(x=[x.min(),x.max()],y=[0,0])\n",
    "    return comparison_plot"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a function that will be useful for our linear progression portion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace({False : int(0), True : int(1)}, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lots of the features are boolean, so I just switched them to integers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    13463\n",
       "2.0     9138\n",
       "3.0     2822\n",
       "1.0     2691\n",
       "4.0     1523\n",
       "Name: Weather_Condition, dtype: int64"
      ]
     },
     "execution_count": 628,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.replace({'Fair':int(0),'Clear':int(0), \n",
    "            'Partly Cloudy':int(1),'Scattered Clouds':int(1),'Haze':int(1),'Patches of Fog':int(1),\n",
    "            'Cloudy':int(2), 'Mostly Cloudy':int(2), 'Overcast':int(2), 'Fair / Windy':int(2),'Mist':int(2),'Smoke':int(2),'Haze / Windy':int(2),\n",
    "            'Light Rain':int(3),'Cloudy / Windy':int(3),'Fog':int(3), 'Light Drizzle':int(3), 'Thunder in the Vicinity':int(3),'Drizzle':int(3),'Light Freezing Fog':int(3),\n",
    "            'Light Rain with Thunder':int(3),'Partly Cloudy / Windy':int(3),'Mostly Cloudy / Windy':int(3),'Fog / Windy':int(3),'Heavy Drizzle':int(3),'N/A Precipitation':int(3),\n",
    "            'Rain':int(4),'Light Snow':int(4),'Heavy Rain':int(4),'Light Rain / Windy':int(4),'Snow':int(4),'Wintry Mix':int(4),'T-Storm':int(4),\n",
    "            'Heavy T-Storm':int(4), 'Heavy Snow':int(4), 'Snow / Windy': int(4),'Heavy Rain / Windy':int(4),'Rain / Windy':int(4),'Thunder':int(4),\n",
    "            'Light Freezing Rain':int(4),'Heavy T-Storm / Windy':int(4),'Light Sleet':int(4),'Ice Pellets':int(4),'Heavy Thunderstorms and Rain':int(4),\n",
    "            'Light Thunderstorms and Rain':int(4), 'Thunderstorms and Rain':int(4),'Heavy Thunderstorms and Snow':int(4),'Light Ice Pellets':int(4),\n",
    "            'Light Freezing Drizzle':int(4),'Heavy Snow / Windy':int(4),'T-Storm / Windy':int(4),'Thunderstorm':int(4),'Light Snow / Windy':int(4)}, inplace=True)\n",
    "df['Weather_Condition'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73.0    557\n",
      "72.0    527\n",
      "70.0    486\n",
      "71.0    465\n",
      "66.0    462\n",
      "       ... \n",
      "20.6      1\n",
      "30.2      1\n",
      "11.6      1\n",
      "21.5      1\n",
      "12.2      1\n",
      "Name: Wind_Chill(F), Length: 420, dtype: int64\n",
      "4760\n"
     ]
    }
   ],
   "source": [
    "print(df['Wind_Chill(F)'].value_counts())\n",
    "print(df['Wind_Chill(F)'].isnull().sum())\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've classified the weather condition features. These are kind of up to interpretation, and actually ended up making the score of the logistic regression slightly less accurate. These should probably be tweaked; then again, maybe there are other feature columns that really ought not be in our logistic regression that is throwing off our data. This dropped the score about 1-2%, and while its still in a decent range getting our accuracy closer to 75% would be best I think."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    18624\n",
       "1.0    11125\n",
       "Name: Night, dtype: int64"
      ]
     },
     "execution_count": 631,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Sunrise_Sunset']=df['Sunrise_Sunset'].replace('Day',int(0))\n",
    "df['Sunrise_Sunset']=df['Sunrise_Sunset'].replace('Night',int(1))\n",
    "df.rename(columns={'Sunrise_Sunset':'Night'}, inplace=True)\n",
    "df.iloc[:,44].value_counts()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 'Sunrise_Sunset' feature actually just tells us if something is night or day. These have been switched to integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Precipitation(in)']=df['Precipitation(in)']*10\n",
    "df.rename(columns={'Precipitation(in)':'Precipitation(tenth_in)'}, inplace=True)\n",
    "\n",
    "\n",
    "for i in df.columns:\n",
    "    if df[i].dtype == float:\n",
    "        df[i] = df[i].round().astype('Int64')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I switched the 'Precipitation' feature to be measured in tenths of an inch. This is because most of these values in inches are floats in a range of 0-2 inches, so when they are rounded and changed to integers the data is simplified to  values of either 0,1, or 2. By changing these values to tenths, we retain more accuracy in our data. This may be something we want to do with some other features, but I have not gone through all of them yet.\n",
    "\n",
    "The loop is just changing every float value in each column to an integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Precipitation(tenth_in)'] = df['Precipitation(tenth_in)'].fillna(value=1000)\n",
    "df.loc[(df['Weather_Condition']==int(4)) & (df['Precipitation(tenth_in)']==1000)  ,'Precipitation(tenth_in)'] = int(2)\n",
    "df.loc[(df['Weather_Condition']!=int(4)) & (df['Precipitation(tenth_in)']==1000)  ,'Precipitation(tenth_in)'] = int(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07941544885177453\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.9077231695085255"
      ]
     },
     "execution_count": 468,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rain = df.copy(deep=True)\n",
    "print(rain['Precipitation(tenth_in)'].mean())\n",
    "rain['Precipitation(tenth_in)']=df['Precipitation(tenth_in)'].replace(int(0),np.nan)\n",
    "\n",
    "rain = rain.dropna(subset=['Precipitation(tenth_in)'])\n",
    "\n",
    "\n",
    "rain['Precipitation(tenth_in)'].mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 29762 entries, 0 to 29761\n",
      "Data columns (total 48 columns):\n",
      " #   Column                   Non-Null Count  Dtype \n",
      "---  ------                   --------------  ----- \n",
      " 0   Unnamed: 0               29762 non-null  int64 \n",
      " 1   ID                       29762 non-null  object\n",
      " 2   Severity                 29762 non-null  int64 \n",
      " 3   Start_Time               29762 non-null  object\n",
      " 4   End_Time                 29762 non-null  object\n",
      " 5   Start_Lat                29762 non-null  Int64 \n",
      " 6   Start_Lng                29762 non-null  Int64 \n",
      " 7   End_Lat                  29762 non-null  Int64 \n",
      " 8   End_Lng                  29762 non-null  Int64 \n",
      " 9   Distance(mi)             29762 non-null  Int64 \n",
      " 10  Description              29762 non-null  object\n",
      " 11  Number                   3630 non-null   Int64 \n",
      " 12  Street                   29762 non-null  object\n",
      " 13  Side                     29762 non-null  object\n",
      " 14  City                     29762 non-null  object\n",
      " 15  County                   29762 non-null  object\n",
      " 16  State                    29762 non-null  object\n",
      " 17  Zipcode                  29762 non-null  object\n",
      " 18  Country                  29762 non-null  object\n",
      " 19  Timezone                 29762 non-null  object\n",
      " 20  Airport_Code             29752 non-null  object\n",
      " 21  Weather_Timestamp        29704 non-null  object\n",
      " 22  Temperature(F)           29639 non-null  Int64 \n",
      " 23  Wind_Chill(F)            25002 non-null  Int64 \n",
      " 24  Humidity(%)              29579 non-null  Int64 \n",
      " 25  Pressure(in)             29693 non-null  Int64 \n",
      " 26  Visibility(mi)           29663 non-null  Int64 \n",
      " 27  Wind_Direction           29555 non-null  object\n",
      " 28  Wind_Speed(mph)          28674 non-null  Int64 \n",
      " 29  Precipitation(tenth_in)  23950 non-null  Int64 \n",
      " 30  Weather_Condition        29637 non-null  object\n",
      " 31  Amenity                  29762 non-null  int64 \n",
      " 32  Bump                     29762 non-null  int64 \n",
      " 33  Crossing                 29762 non-null  int64 \n",
      " 34  Give_Way                 29762 non-null  int64 \n",
      " 35  Junction                 29762 non-null  int64 \n",
      " 36  No_Exit                  29762 non-null  int64 \n",
      " 37  Railway                  29762 non-null  int64 \n",
      " 38  Roundabout               29762 non-null  int64 \n",
      " 39  Station                  29762 non-null  int64 \n",
      " 40  Stop                     29762 non-null  int64 \n",
      " 41  Traffic_Calming          29762 non-null  int64 \n",
      " 42  Traffic_Signal           29762 non-null  int64 \n",
      " 43  Turning_Loop             29762 non-null  int64 \n",
      " 44  Sunrise_Sunset           29749 non-null  object\n",
      " 45  Civil_Twilight           29749 non-null  object\n",
      " 46  Nautical_Twilight        29749 non-null  object\n",
      " 47  Astronomical_Twilight    29749 non-null  object\n",
      "dtypes: Int64(13), int64(15), object(20)\n",
      "memory usage: 11.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=np.genfromtxt('CT_Accidents.csv',delimiter=',',skip_header=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.columns[[2,22,24,25,26,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44]]\n",
    "data = df[features].dropna()\n",
    "data=data[features].to_numpy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28552, 21)\n",
      "(28552, 1)\n",
      "(28552, 22)\n"
     ]
    }
   ],
   "source": [
    "X = data[:,1:]\n",
    "Y = data[:,0]\n",
    "print(np.shape(X))\n",
    "ones = np.ones((X.shape[0],1))\n",
    "print(np.shape(ones))\n",
    "x_new = np.hstack((X,ones))\n",
    "print(np.shape(x_new))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above I just quickly put together a data variable that takes our dataframe and formats it into arrays. I think this will be a necessary first step in preparing the data for Linear Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    24766\n",
       "1     4996\n",
       "Name: Severity, dtype: int64"
      ]
     },
     "execution_count": 637,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Severity']=df['Severity'].replace(int(1),int(0))\n",
    "df['Severity']=df['Severity'].replace(int(2),int(0))\n",
    "df['Severity']=df['Severity'].replace(int(3),int(1))\n",
    "df['Severity']=df['Severity'].replace(int(4),int(1))\n",
    "\n",
    "df['Severity'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    24766\n",
       "1     4996\n",
       "Name: Severity, dtype: int64"
      ]
     },
     "execution_count": 638,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Severity'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I have reformated the 'Severity' feature that can act as our target. While we can use the original 4 classes for Linear Regression, restricting it to 2 will let us do our Binary Logistic Regression. I just did this after the Linear & PCA section, but we could always just make a new dataset out of this parameter.\n",
    "\n",
    "In the original format, there are only 4 accidents with 'Severity'=1, so switching the classes to just two really shouldnt skew the data much at all. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "df = df.dropna(subset=['Temperature(F)','Humidity(%)','Pressure(in)','Visibility(mi)','Wind_Speed(mph)','Weather_Condition','Night'])\n",
    "print(df.isnull().values.any())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a good amount of nan values in each of our numerical feature columns. Here I just dropped every row with them, but we can assess which variables may be better to replace nan values with the average of that feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=10000)"
      ]
     },
     "execution_count": 655,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = df.columns[[22,24,25,26,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44]]\n",
    "L=LogisticRegression(max_iter=10000, solver='lbfgs')\n",
    "x_train, x_test, y_train, y_test = train_test_split(df[features].values, df['Severity'].values)\n",
    "L.fit(x_train,y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I just through in the numerical values into the logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8372093023255814"
      ]
     },
     "execution_count": 656,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L.score(x_test,y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Around 70% is an okay start but hopefully we can improve. Another thing I haven't done yet is mess with the features that can be considered dependent variable. There might not be any though, since it looks like the variables dealing with time of day have been organized so there's probably no overlap. I havent formated those types of features to numerical values yet either. I feel like once we include those, our logistic regression should improve as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 28552 entries, 0 to 29761\n",
      "Data columns (total 22 columns):\n",
      " #   Column                   Non-Null Count  Dtype\n",
      "---  ------                   --------------  -----\n",
      " 0   Severity                 28552 non-null  int64\n",
      " 1   Temperature(F)           28552 non-null  Int64\n",
      " 2   Humidity(%)              28552 non-null  Int64\n",
      " 3   Pressure(in)             28552 non-null  Int64\n",
      " 4   Visibility(mi)           28552 non-null  Int64\n",
      " 5   Wind_Speed(mph)          28552 non-null  Int64\n",
      " 6   Precipitation(tenth_in)  28552 non-null  Int64\n",
      " 7   Weather_Condition        28552 non-null  Int64\n",
      " 8   Amenity                  28552 non-null  int64\n",
      " 9   Bump                     28552 non-null  int64\n",
      " 10  Crossing                 28552 non-null  int64\n",
      " 11  Give_Way                 28552 non-null  int64\n",
      " 12  Junction                 28552 non-null  int64\n",
      " 13  No_Exit                  28552 non-null  int64\n",
      " 14  Railway                  28552 non-null  int64\n",
      " 15  Roundabout               28552 non-null  int64\n",
      " 16  Station                  28552 non-null  int64\n",
      " 17  Stop                     28552 non-null  int64\n",
      " 18  Traffic_Calming          28552 non-null  int64\n",
      " 19  Traffic_Signal           28552 non-null  int64\n",
      " 20  Turning_Loop             28552 non-null  int64\n",
      " 21  Night                    28552 non-null  Int64\n",
      "dtypes: Int64(8), int64(14)\n",
      "memory usage: 5.2 MB\n"
     ]
    }
   ],
   "source": [
    "df[features].info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
